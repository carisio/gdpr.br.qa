{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1504f1bb-dfc2-4d92-bc2b-842c919b2d87",
   "metadata": {},
   "source": [
    "# 1. Prompt the LLM with only the question (without any context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d666c315-7cda-4b79-b621-6db3ec6cd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from groq import Groq\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7473cce9-cbf8-466d-87a7-ec7bcde7ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KEY OpenAI ········\n",
      "KEY DeepSeek ········\n",
      "KEY Groq ········\n",
      "KEY Maritaca ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_KEY = getpass(\"KEY OpenAI\")\n",
    "DEEPSEEK_KEY = getpass(\"KEY DeepSeek\")\n",
    "GROQ_API = getpass(\"KEY Groq\")\n",
    "SABIA_API = getpass(\"KEY Maritaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0531056e-7a63-4e97-842c-e10da4873ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"dataset/gdpr-br-qa.jsonl\"\n",
    "embeddings_dataset_file = \"dataset/emb_gdpr-br-qa.pkl\"\n",
    "chunks_lgpd_file = \"lgpd/chunks_lgpd.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fbe6a3-8741-4178-bf82-909129470607",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg_rag = \"\"\"\n",
    "Seu papel é resolver questões sobre a LGPD. Para isso, você deverá obedecer às seguintes regras:\n",
    "\n",
    "1. O usuário irá te passar uma questão que você deverá responder.\n",
    "2. Essa questão pode ser de dois tipos. Pode ser de múltipla escolha, situação em que você deverá avaliar o enunciado e decidir por uma das alternativas apresentadas, ou pode ser de <CERTO> ou <ERRADO>, situação em que você deverá avaliar se o enunciado está correto ou não. O que diferencia as questões é a presença ou ausência de alternativas. Se tiver alternativas, é de múltipla escolha. Se não houver, é de <CERTO> ou <ERRADO>\n",
    "3. A sua resposta deve ser direta, sem nenhuma marcação (pontuação, aspas ou qualquer outro caractere além da resposta).\n",
    "3.1. Se for uma questão de múltiplica escolha, indique apenas a letra que responde ao enunciado.\n",
    "3.2. Se for uma questão de <CERTO> ou <ERRADO> responda com \"Certo\" (para certo) ou \"Errado\" para errado.\n",
    "\n",
    "Segue alguns trechos da LGPD que podem ajudar na solução da questão:\n",
    "\n",
    "{trechos}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106dcb86-2923-466e-820e-48109893d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros dos modelos\n",
    "\n",
    "RAG_3_GPT_4o_MINI = {\n",
    "    \"EXPERIMENT_NAME\": \"rag_3_gpt-4o-mini-2024-07-18\",\n",
    "    \"CLIENT\": OpenAI(api_key=OPENAI_KEY, base_url=None),\n",
    "    \"MODEL\": \"gpt-4o-mini-2024-07-18\",\n",
    "    \"SYSTEM_MSG\": system_msg_rag,\n",
    "    \"N_CHUNKS\": 3,\n",
    "}\n",
    "\n",
    "RAG_3_DEEPSEEK_CHAT = {\n",
    "    \"EXPERIMENT_NAME\": \"rag_3_deepseek-chat\",\n",
    "    \"CLIENT\": OpenAI(api_key=DEEPSEEK_KEY, base_url=\"https://api.deepseek.com\"),\n",
    "    \"MODEL\": \"deepseek-chat\",\n",
    "    \"SYSTEM_MSG\": system_msg_rag,\n",
    "    \"N_CHUNKS\": 3,\n",
    "}\n",
    "\n",
    "RAG_3_LLAMA3_3 = {\n",
    "    \"EXPERIMENT_NAME\": \"rag_3_llama-3.3-70b-versatile\",\n",
    "    \"CLIENT\": Groq(api_key=GROQ_API),\n",
    "    \"MODEL\": \"llama-3.3-70b-versatile\",\n",
    "    \"SYSTEM_MSG\": system_msg_rag,\n",
    "    \"N_CHUNKS\": 3,\n",
    "}\n",
    "\n",
    "RAG_3_SABIA3 = {\n",
    "    \"EXPERIMENT_NAME\": \"rag_3_sabia-3-2024-12-11\",\n",
    "    \"CLIENT\": OpenAI(api_key=SABIA_API, base_url=\"https://chat.maritaca.ai/api\"),\n",
    "    \"MODEL\": \"sabia-3-2024-12-11\",\n",
    "    \"SYSTEM_MSG\": system_msg_rag,\n",
    "    \"N_CHUNKS\": 3,\n",
    "}\n",
    "\n",
    "EXPERIMENTS = [RAG_3_GPT_4o_MINI, RAG_3_DEEPSEEK_CHAT, RAG_3_LLAMA3_3, RAG_3_SABIA3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c3d5d5-cbb2-4b91-986a-f9ecafaf97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o dataset e os arquivos com embeddings\n",
    "df_dataset = pd.read_json(dataset_file, lines=True, encoding='utf-8')\n",
    "df_embeddings_dataset = pd.read_pickle(embeddings_dataset_file)\n",
    "df_chunks_lgpd = pd.read_pickle(chunks_lgpd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638f0155-284e-4c8a-966c-5fbb2df8d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retornar os chunks mais próximos\n",
    "def get_chunks(id_questao, n_chunks = 3):\n",
    "    questao = df_dataset['Formatted Question'][df_dataset.ID == id_questao].values[0]\n",
    "    emb_questao = df_embeddings_dataset['emb'][df_dataset.ID == id_questao].values[0]\n",
    "\n",
    "    df_similares = df_chunks_lgpd.copy()\n",
    "    \n",
    "    df_similares['similarity'] = df_similares.emb.apply(lambda x: cosine_similarity([x], [emb_questao])[0][0])\n",
    "    \n",
    "    df_similares = df_similares.sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "    return questao, df_similares.chunk.values[:n_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65589d13-c71a-4547-900e-4fef42b7c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns to represent the experiment results\n",
    "for experiment in EXPERIMENTS:\n",
    "    experiment_name = experiment['EXPERIMENT_NAME']\n",
    "    llm_model = experiment['MODEL']\n",
    "\n",
    "    # Create columns for the experiment results\n",
    "    if experiment_name not in df_dataset.columns:\n",
    "        df_dataset[experiment_name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb1d6e9f-4bbf-4969-8edc-e5aa47680709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_llm(experiment, id_question):\n",
    "    llm_model = experiment['MODEL']\n",
    "    client = experiment['CLIENT']\n",
    "    n_chunks = experiment['N_CHUNKS']\n",
    "    \n",
    "    formatted_question, chunks = get_chunks(id_question, n_chunks)\n",
    "\n",
    "    chunks_str = \"\\n\".join([f\"Trecho {i+1}:\\n{item}\\n\" for i, item in enumerate(chunks)])\n",
    "    system_msg = experiment['SYSTEM_MSG'].format(trechos=chunks_str)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": formatted_question},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3741cc0-fd6f-4d30-ab16-36ec567f23d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: rag_3_gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 12898.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: rag_3_deepseek-chat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 15669.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: rag_3_llama-3.3-70b-versatile\n",
      "Experiment: rag_3_sabia-3-2024-12-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [10:58<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run each experiment\n",
    "min_elapsed_time = 0\n",
    "for experiment in EXPERIMENTS:\n",
    "    experiment_name = experiment['EXPERIMENT_NAME']\n",
    "    llm_model = experiment['MODEL']\n",
    "    \n",
    "    print(f\"Experiment: {experiment_name}\")\n",
    "\n",
    "    if 'llama' in experiment_name:\n",
    "        continue\n",
    "        \n",
    "    for index, row in tqdm(df_dataset.iterrows(), total=len(df_dataset)):\n",
    "        start_time = time.time()\n",
    "        # Run only if we don't have the results\n",
    "        if pd.isna(row[experiment_name]) or row[experiment_name] == '':\n",
    "            df_dataset.at[index, experiment_name] = get_answer_llm(experiment, row.ID)\n",
    "            \n",
    "            # Update the dataset with the results\n",
    "            with open(dataset_file, 'w', encoding='utf-8') as f:\n",
    "                df_dataset.to_json(f, orient='records', lines=True, force_ascii=False)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < min_elapsed_time and 'llama' in experiment_name:\n",
    "                time.sleep(min_elapsed_time - elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56945c4c-ea49-4624-8b02-782965a460e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: rag_3_gpt-4o-mini-2024-07-18. Avg: 0.8385714285714285.\n",
      "Experiment: rag_3_deepseek-chat. Avg: 0.9057142857142857.\n",
      "Experiment: rag_3_llama-3.3-70b-versatile. Avg: 0.03571428571428571.\n",
      "Experiment: rag_3_sabia-3-2024-12-11. Avg: 0.8842857142857142.\n"
     ]
    }
   ],
   "source": [
    "# Show results for each experiment\n",
    "for experiment in EXPERIMENTS:\n",
    "    experiment_name = experiment['EXPERIMENT_NAME']\n",
    "    avg = (df_dataset['Answer'] == df_dataset[experiment_name]).mean()\n",
    "    print(f\"Experiment: {experiment_name}. Avg: {avg}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
